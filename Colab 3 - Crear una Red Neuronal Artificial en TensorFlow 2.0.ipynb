{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShelEJtVLTEN"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joanby/tensorflow2/blob/master/Colab%203%20-%20Crear%20una%20Red%20Neuronal%20Artificial%20en%20TensorFlow%202.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJr4nMgyb9oS"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png\" />\n",
        "  Imagen cortesía de: https://www.kaggle.com/\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVF9I9v6Zipb"
      },
      "source": [
        "## Paso 1: Instalar las dependencias y configurar el entorno de GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "WS6fShx3Za4O",
        "outputId": "992d8abe-0f1c-4d37-966b-da81502a91b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 93kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.16.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0.alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0.alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (41.0.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow-gpu==2.3.0\n",
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjlnjPnjWYFw"
      },
      "source": [
        "## Paso 2: Importar las dependencias necesarias para el proyecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yt0-hrch6rZw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_vv9AXUnZW78",
        "outputId": "74ef1892-f573-4a30-807f-f439aa616590"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.17.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2OiUS-kWkJU"
      },
      "source": [
        "## Paso 3: Pre procesado de datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfoFiEEXYj1"
      },
      "source": [
        "### Cargar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "-lCgz6UC8pKT"
      },
      "outputs": [],
      "source": [
        "#Cargar el dataset Fashion Mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYxeEHzDXdSs"
      },
      "source": [
        "### Normalizar las imágenes\n",
        "\n",
        "Se divide cada imagen en los conjunto de entrenamiento y  de testing entre el valor máximo de cada uno de los píxeles (255).\n",
        "\n",
        "De este modo, cada píxel se hallará en el rango [0, 1]. Al normalizar las imágenes, nos aseguramos que nuestro modelo de RNA entrenará más rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "zvWzsB3G9IU8"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "lo--rpqo9ZtA"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBacLmGIX0Es"
      },
      "source": [
        "### Redimensionar el dataset\n",
        "\n",
        "Como vamos a utilizar una red neuronal totalmente conectada, vamos a redimensionar los subconjuntos de entrenamiento y testing a formato de vector en lugar de en formato de matriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "2Tao7pom-grn"
      },
      "outputs": [],
      "source": [
        "#Como cada imagen tiene 28x28 píxeles, usamos la función reshape en todo el dataset de entrenamiento para convertirlo\n",
        "# en vectores de tamaño [-1 (todos los elementos), anchura * altura]\n",
        "X_train = X_train.reshape(-1, 28*28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9MbMrg9-kr_",
        "outputId": "47b92670-bf42-4bba-ced0-d8ee33d89f82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Y_duQGtbCTTL"
      },
      "outputs": [],
      "source": [
        "#Redimensionamos el conjunto de testing del mismo modo\n",
        "X_test = X_test.reshape(-1, 28*28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5aDsaYSYmXD"
      },
      "source": [
        "## Paso 4: Construir la Red Neuronal Artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l30aZ6-GYtUP"
      },
      "source": [
        "### Definir el modelo\n",
        "\n",
        "Simplemente se define un objeto de modelo Sequential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "xmfogzmn9kqv"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNzLOAK5Y-mR"
      },
      "source": [
        "### Añadir la primera capa totalmente conectada (capa Densa)\n",
        "\n",
        "Hyper-parametros de la capa:\n",
        "- número de unidades/neuronas: 128\n",
        "- función de activación: ReLU\n",
        "- input_shape: (784, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "GBsfDyGE-FX5"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, )))\n",
        "#model.add(tf.keras.layers.Dense(units=64, activation='relu' ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwqx1wZUa1rH"
      },
      "source": [
        "### Añadir una capa de Dropout\n",
        "\n",
        "Dropout es una técnica de Regularization donde aleatoriamente se asignan a ciertas neuronas de la red el valor cero. De este modo, mientras se entrena, estas neuronas no actualizarán sus valores. Al tener cierto porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "tAmpLPlr-pOX"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqvyDvNbzwN"
      },
      "source": [
        "### Añadir la segunda capa (capa de salida)\n",
        "\n",
        "- unidades: número de clases (10 en el caso del Fashion MNIST)\n",
        "- función de activación: 'softmax' (probabilidades de cada clase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "OmkUuF9Y-3mG"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRsMjsvcOua"
      },
      "source": [
        "### Compilar el modelo\n",
        "\n",
        "- Optimizer: Adam\n",
        "- Loss: Sparse softmax (categorical) crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "nbW3xeRK_CrN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "8dQOL_EtChrN",
        "outputId": "aefe5704-ee76-439f-fbb4-e2904efd6e42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxIIFU1cany"
      },
      "source": [
        "### Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-_oLiE0_3A2",
        "outputId": "5dd767c8-7ae0-43ca-96fb-2d0a6c761d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 1.0218 - sparse_categorical_accuracy: 0.6708 - val_loss: 0.5483 - val_sparse_categorical_accuracy: 0.8143\n",
            "Epoch 2/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5246 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.4859 - val_sparse_categorical_accuracy: 0.8328\n",
            "Epoch 3/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.4563 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 4/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8490 - val_loss: 0.4310 - val_sparse_categorical_accuracy: 0.8496\n",
            "Epoch 5/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.3972 - sparse_categorical_accuracy: 0.8625 - val_loss: 0.4137 - val_sparse_categorical_accuracy: 0.8555\n",
            "Epoch 6/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3875 - sparse_categorical_accuracy: 0.8653 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8594\n",
            "Epoch 7/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3747 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.3918 - val_sparse_categorical_accuracy: 0.8621\n",
            "Epoch 8/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3604 - sparse_categorical_accuracy: 0.8744 - val_loss: 0.3846 - val_sparse_categorical_accuracy: 0.8646\n",
            "Epoch 9/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.3492 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 10/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3411 - sparse_categorical_accuracy: 0.8798 - val_loss: 0.3796 - val_sparse_categorical_accuracy: 0.8674\n",
            "Epoch 11/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8827 - val_loss: 0.3652 - val_sparse_categorical_accuracy: 0.8719\n",
            "Epoch 12/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.3237 - sparse_categorical_accuracy: 0.8850 - val_loss: 0.3583 - val_sparse_categorical_accuracy: 0.8745\n",
            "Epoch 13/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3160 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.3560 - val_sparse_categorical_accuracy: 0.8749\n",
            "Epoch 14/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.3112 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.3512 - val_sparse_categorical_accuracy: 0.8769\n",
            "Epoch 15/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.3067 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.3472 - val_sparse_categorical_accuracy: 0.8774\n",
            "Epoch 16/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8753\n",
            "Epoch 17/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.2914 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.3498 - val_sparse_categorical_accuracy: 0.8786\n",
            "Epoch 18/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.3406 - val_sparse_categorical_accuracy: 0.8814\n",
            "Epoch 19/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2868 - sparse_categorical_accuracy: 0.8985 - val_loss: 0.3379 - val_sparse_categorical_accuracy: 0.8802\n",
            "Epoch 20/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2830 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.3341 - val_sparse_categorical_accuracy: 0.8820\n",
            "Epoch 21/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.3341 - val_sparse_categorical_accuracy: 0.8811\n",
            "Epoch 22/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.9016 - val_loss: 0.3318 - val_sparse_categorical_accuracy: 0.8808\n",
            "Epoch 23/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.2689 - sparse_categorical_accuracy: 0.9058 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 0.8827\n",
            "Epoch 24/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2691 - sparse_categorical_accuracy: 0.9034 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8826\n",
            "Epoch 25/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2649 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8828\n",
            "Epoch 26/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9078 - val_loss: 0.3246 - val_sparse_categorical_accuracy: 0.8850\n",
            "Epoch 27/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2588 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.3242 - val_sparse_categorical_accuracy: 0.8846\n",
            "Epoch 28/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2529 - sparse_categorical_accuracy: 0.9093 - val_loss: 0.3213 - val_sparse_categorical_accuracy: 0.8862\n",
            "Epoch 29/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.3211 - val_sparse_categorical_accuracy: 0.8876\n",
            "Epoch 30/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.3181 - val_sparse_categorical_accuracy: 0.8867\n",
            "Epoch 31/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2403 - sparse_categorical_accuracy: 0.9130 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.8872\n",
            "Epoch 32/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.9127 - val_loss: 0.3168 - val_sparse_categorical_accuracy: 0.8866\n",
            "Epoch 33/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2432 - sparse_categorical_accuracy: 0.9105 - val_loss: 0.3189 - val_sparse_categorical_accuracy: 0.8876\n",
            "Epoch 34/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2385 - sparse_categorical_accuracy: 0.9161 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8847\n",
            "Epoch 35/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2292 - sparse_categorical_accuracy: 0.9173 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.8886\n",
            "Epoch 36/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2308 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.3140 - val_sparse_categorical_accuracy: 0.8899\n",
            "Epoch 37/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2296 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.3169 - val_sparse_categorical_accuracy: 0.8875\n",
            "Epoch 38/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2282 - sparse_categorical_accuracy: 0.9179 - val_loss: 0.3138 - val_sparse_categorical_accuracy: 0.8890\n",
            "Epoch 39/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8891\n",
            "Epoch 40/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.9200 - val_loss: 0.3195 - val_sparse_categorical_accuracy: 0.8875\n",
            "Epoch 41/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2211 - sparse_categorical_accuracy: 0.9200 - val_loss: 0.3117 - val_sparse_categorical_accuracy: 0.8889\n",
            "Epoch 42/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2142 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.3135 - val_sparse_categorical_accuracy: 0.8886\n",
            "Epoch 43/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2112 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.3114 - val_sparse_categorical_accuracy: 0.8898\n",
            "Epoch 44/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2129 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.8909\n",
            "Epoch 45/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2067 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8898\n",
            "Epoch 46/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2073 - sparse_categorical_accuracy: 0.9258 - val_loss: 0.3116 - val_sparse_categorical_accuracy: 0.8923\n",
            "Epoch 47/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2119 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.3135 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 48/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2101 - sparse_categorical_accuracy: 0.9224 - val_loss: 0.3144 - val_sparse_categorical_accuracy: 0.8879\n",
            "Epoch 49/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2054 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.3070 - val_sparse_categorical_accuracy: 0.8925\n",
            "Epoch 50/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.8926\n",
            "Epoch 51/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.3073 - val_sparse_categorical_accuracy: 0.8952\n",
            "Epoch 52/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.3113 - val_sparse_categorical_accuracy: 0.8928\n",
            "Epoch 53/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1945 - sparse_categorical_accuracy: 0.9308 - val_loss: 0.3076 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 54/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1997 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.3150 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 55/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9304 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.8938\n",
            "Epoch 56/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1909 - sparse_categorical_accuracy: 0.9311 - val_loss: 0.3041 - val_sparse_categorical_accuracy: 0.8954\n",
            "Epoch 57/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.8952\n",
            "Epoch 58/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9309 - val_loss: 0.3098 - val_sparse_categorical_accuracy: 0.8909\n",
            "Epoch 59/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1873 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.3137 - val_sparse_categorical_accuracy: 0.8942\n",
            "Epoch 60/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8962\n",
            "Epoch 61/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.3077 - val_sparse_categorical_accuracy: 0.8948\n",
            "Epoch 62/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3123 - val_sparse_categorical_accuracy: 0.8937\n",
            "Epoch 63/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1785 - sparse_categorical_accuracy: 0.9352 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 64/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.8947\n",
            "Epoch 65/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1764 - sparse_categorical_accuracy: 0.9371 - val_loss: 0.3095 - val_sparse_categorical_accuracy: 0.8933\n",
            "Epoch 66/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.8944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e65cae06e90>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0)\n",
        "model.fit(X_train, y_train,  validation_data=(X_test, y_test), epochs=100, callbacks=[callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj23nxmtcrhd"
      },
      "source": [
        "### Evaluación del modelo y predicción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nQCioOmAL7i",
        "outputId": "e453d5b1-d88e-432f-da1f-2c3bcca9b9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3071 - sparse_categorical_accuracy: 0.8919\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozv2YVlxcx1h",
        "outputId": "213113df-e304-4b03-a3ed-2eb681d8e724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8953999876976013\n"
          ]
        }
      ],
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noi53-uq9yhl"
      },
      "source": [
        "## Paso 5 : Guardar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMFm-Z9I99R5"
      },
      "source": [
        "### Guardar la arquitectura (topoligía) de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT7pmXWO9xxM"
      },
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"fashion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UDk8L4A-CQX"
      },
      "source": [
        "### Guardar los pesos de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0ZOVcC498Mp"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"fashion_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Colab 3 - Crear una Red Neuronal Artificial en TensorFlow 2.0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}